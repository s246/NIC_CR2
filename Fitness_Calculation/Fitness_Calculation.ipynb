{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51be12d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "file_name='TTP Problems small.txt'\n",
    "\n",
    "\n",
    "\n",
    "#global vars\n",
    "global dict_constants #constanst of current problem\n",
    "global nodes_df\n",
    "global items_df\n",
    "\n",
    "\n",
    "def read_data(file_name):\n",
    "    global dict_constants, nodes_df, items_df\n",
    "\n",
    "    dict_constants={}\n",
    "\n",
    "    #read txt file on absolute path\n",
    "    with open(f\"./{file_name}\") as raw:\n",
    "        data = raw.read()\n",
    "        nodes_pos=data.split('ITEMS SECTION')[0]\n",
    "        items_vals = data.split('ITEMS SECTION')[1]\n",
    "\n",
    "        #CONSTANTS\n",
    "        for global_features in nodes_pos.split('\\n')[2:8]:\n",
    "            temp = global_features.split('\\t')\n",
    "            var_name = temp[0].replace((':'),' ').strip()\n",
    "            var_val = temp[1]\n",
    "            dict_constants[var_name] = float(var_val)\n",
    "\n",
    "        #NODES POSTIONS\n",
    "        all_nodes_list = []\n",
    "        for vals in nodes_pos.split('\\n')[10:-1]:\n",
    "            temp = vals.split('\\t')\n",
    "            temp = [float(t) for t in temp]\n",
    "            all_nodes_list.append(temp)\n",
    "\n",
    "        nodes_df = pd.DataFrame(all_nodes_list, columns=['node_index', 'x_coor', 'y_coor'])\n",
    "        nodes_df['node_index'] = nodes_df['node_index'].astype('int')\n",
    "\n",
    "\n",
    "        #ITEMS\n",
    "        all_items_list = []\n",
    "        for vals in items_vals.split('\\n')[1:-1]:\n",
    "            temp = vals.split('\\t')\n",
    "            temp = [float(t) for t in temp]\n",
    "            all_items_list.append(temp)\n",
    "\n",
    "        items_df = pd.DataFrame(all_items_list, columns=['item_index','profit','weight','assigned_node'])\n",
    "        items_df['item_index']= items_df['item_index'].astype('int')\n",
    "        items_df['assigned_node'] = items_df['assigned_node'].astype('int')\n",
    "\n",
    "    #close file\n",
    "    raw.close()\n",
    "\n",
    "def generate_random_initial_population_knappsack(pop_size,dimension):\n",
    "    global number_fitness_eval #set global var\n",
    "\n",
    "    #start at zero evals\n",
    "    number_fitness_eval=0\n",
    "\n",
    "    #population list\n",
    "    population = []\n",
    "\n",
    "    #use numpy random int between 0-1 to create solutions with size of number of bags [0,1,0,0,1.....] to 100\n",
    "    for i in range(0, pop_size):\n",
    "        actual_sol = np.random.randint(2, size=int(dimension))\n",
    "        population.append(actual_sol)\n",
    "\n",
    "    return population\n",
    "\n",
    "\n",
    "\n",
    "read_data(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d2875af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     item_index  profit  weight  assigned_node\n",
      "0             1     1.0  1008.0              2\n",
      "1             2   896.0  1006.0              3\n",
      "2             3   367.0  1006.0              4\n",
      "3             4   690.0  1001.0              5\n",
      "4             5   613.0  1006.0              6\n",
      "..          ...     ...     ...            ...\n",
      "489        1210   132.0  1007.0             95\n",
      "490        1211    20.0  1008.0             96\n",
      "491        1212   975.0  1002.0             97\n",
      "492        1213    29.0  1006.0             98\n",
      "493        1214   681.0  1004.0             99\n",
      "\n",
      "[494 rows x 4 columns]\n",
      "    node_index  x_coor  y_coor\n",
      "0            1   288.0   149.0\n",
      "1            2   288.0   129.0\n",
      "2            3   270.0   133.0\n",
      "3            4   256.0   141.0\n",
      "4            5   256.0   157.0\n",
      "..         ...     ...     ...\n",
      "95          96    16.0    17.0\n",
      "96          97    24.0    17.0\n",
      "97          98    32.0    17.0\n",
      "98          99    44.0    11.0\n",
      "99         100    56.0     9.0\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "{'DIMENSION': 280.0, 'NUMBER OF ITEMS': 1395.0, 'CAPACITY OF KNAPSACK': 637010.0, 'MIN SPEED': 0.1, 'MAX SPEED': 1.0, 'RENTING RATIO': 72.7}\n"
     ]
    }
   ],
   "source": [
    "print(items_df)\n",
    "print(nodes_df)\n",
    "print(dict_constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "858dc89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random(item, node):#A sequence of random numbers generated for the purpose of testing the program\n",
    "    import random\n",
    "    from sklearn.utils import shuffle\n",
    "    \n",
    "    length = len(item)\n",
    "    \n",
    "    random_item = [random.randint(0, 1) for i in range(length)]\n",
    "    \n",
    "    print(random_item)\n",
    "    \n",
    "    #print(node['node_index'])\n",
    "    node_index = node['node_index'].copy()\n",
    "    #print(type(node_index))\n",
    "    #node_index = node_index.reset_index()\n",
    "    random_node = shuffle(node_index)\n",
    "    #print(random_node)\n",
    "    random_node = random_node.reset_index()\n",
    "    \n",
    "    random_node = random_node.drop(columns = ['index'])\n",
    "    print(random_node)\n",
    "    \n",
    "    return(random_item, random_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84215004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eul_dis(node1, node2):#Calculation of Euclidean distance\n",
    "    #print(node1['x_coor'].iloc[0])\n",
    "    #print(node1)\n",
    "    dis = (((node1['x_coor'].iloc[0] - node2['x_coor'].iloc[0]) ** 2) + ((node1['y_coor'].iloc[0] - node2['y_coor'].iloc[0]) ** 2)) ** 0.5\n",
    "    #print(dis,'dis')\n",
    "    return(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce715843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cul_dis(node, n_df):#Calculate the length of each path\n",
    "    dis_df = pd.DataFrame(np.zeros(len(node['node_index'])))\n",
    "    #print(dis_df)\n",
    "    #print(n_df.iloc[7])\n",
    "    j = 0\n",
    "    for i in range(len(node['node_index'])):\n",
    "        #print(node['node_index'][i])\n",
    "        if i != len((node['node_index'])) - 1:\n",
    "            #print(i)\n",
    "            node1 = n_df.loc[n_df['node_index'] == node['node_index'][i]]\n",
    "            node2 = n_df.loc[n_df['node_index'] == node['node_index'][i+1]]\n",
    "            dis_df[0].iloc[j] = eul_dis(node1, node2)\n",
    "            #print(dis_df)\n",
    "            j += 1\n",
    "        else:\n",
    "            node1 = n_df.loc[n_df['node_index'] == node['node_index'][i]]\n",
    "            node2 = n_df.loc[n_df['node_index'] == node['node_index'][0]]\n",
    "            dis_df[0].iloc[j] = eul_dis(node1, node2)\n",
    "            j += 1\n",
    "    #print(dis_df)\n",
    "    return(dis_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69bcc2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cul_weight_speed_profit(node, new_i_df, min_sp, max_sp, capacity):#Calculate the weight, profit and speed after passing each point\n",
    "    wei_df = pd.DataFrame(np.zeros(len(node['node_index'])))\n",
    "    pro_df = pd.DataFrame(np.zeros(len(node['node_index'])))\n",
    "    node['weight'] = wei_df\n",
    "    node['profit'] = pro_df\n",
    "    \n",
    "    for i in range(len(new_i_df)):\n",
    "        \n",
    "        node_index = node[node['node_index'] == new_i_df['assigned_node'].iloc[i]].index[0]\n",
    "        \n",
    "        node['weight'][node_index] += new_i_df['weight'].iloc[i]\n",
    "        node['profit'][node_index] += new_i_df['profit'].iloc[i]\n",
    "    \n",
    "    node['cumsum_w'] = node['weight'].cumsum(axis = 0)\n",
    "    node['cumsum_p'] = node['profit'].cumsum(axis = 0)\n",
    "    node['speed'] = node['cumsum_w'].map(lambda x: max_sp - (x / capacity * (max_sp - min_sp)))\n",
    "    #print(node)\n",
    "    return(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2713a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cul_time(node, n_df, item, i_df, min_sp, max_sp, capacity):#Calculate the time traveled on each road\n",
    "    #print(node)\n",
    "    #print(n_df)\n",
    "    #print(item)\n",
    "    #print(i_df)\n",
    "    print(min_sp, max_sp, capacity)\n",
    "    di_df = cul_dis(node, n_df)\n",
    "    node['distance'] = di_df\n",
    "    i_df['item'] = item\n",
    "    new_i_df = i_df.copy()\n",
    "    new_i_df = new_i_df[new_i_df['item'] != 0]\n",
    "    print(new_i_df)\n",
    "    node = cul_weight_speed_profit(node, new_i_df, min_sp, max_sp, capacity)\n",
    "    node['time'] = node.apply(lambda x: x['distance'] / x['speed'], axis = 1)\n",
    "    print(node)\n",
    "    return(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4616db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cul_fitness(node):#Calculate the fitness.\n",
    "    \n",
    "    #Normalize time and profit to reduce errors caused by data size gaps.\n",
    "    time_max = node['time'].max()\n",
    "    time_min = node['time'].min()\n",
    "    node['normal_time'] = node['time'].map(lambda x: (x - time_min) / (time_max - time_min))\n",
    "    pro_max = node['profit'].max()\n",
    "    pro_min = node['profit'].min()\n",
    "    node['normal_profit'] = node['profit'].map(lambda x: (x - pro_min) / (pro_max - pro_min))\n",
    "    \n",
    "    #Fitness at each point is the result of profit minus time.\n",
    "    node['fitness'] = node.apply(lambda x: x['normal_profit'] - x['normal_time'], axis = 1)\n",
    "    print(node)\n",
    "    \n",
    "    #Total fitness is the sum of all individual fitness.\n",
    "    total_fitness = node['fitness'].sum()\n",
    "    print(total_fitness, 'total_fitness')\n",
    "    \n",
    "    #Start calculating the total fitness for each point and then normalize it to be able to compare it to the original data to see how effective fitness is\n",
    "    node['cumsum_f'] = node['fitness'].cumsum(axis = 0)\n",
    "    cu_f_max = node['cumsum_f'].max()\n",
    "    cu_f_min = node['cumsum_f'].min()\n",
    "    node['normal_c_f'] = node['cumsum_f'].map(lambda x: (x - cu_f_min) / (cu_f_max - cu_f_min))\n",
    "    return(node, total_fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2277ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fig(node):\n",
    "    \n",
    "    #n_node = node[['normal_time', 'normal_profit', 'fitness']].copy()\n",
    "    t_f_node = node[['normal_time', 'normal_c_f']].copy()\n",
    "    t_f_node.plot()\n",
    "    p_f_node = node[['normal_profit', 'normal_c_f']].copy()\n",
    "    p_f_node.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa06b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_calculation(a, nodes_df, items_df, dict_constants):\n",
    "    #random_item, random_node = generate_random(items_df, nodes_df)\n",
    "\n",
    "    b = {\"node_index\" : a[1]}\n",
    "    random_node = pd.DataFrame(b)\n",
    "    random_node.columns = ['node_index']\n",
    "    random_item = a[0]\n",
    "    \n",
    "    new_node = cul_time(random_node, nodes_df, random_item, items_df,  dict_constants['MIN SPEED'], dict_constants['MAX SPEED'], dict_constants['CAPACITY OF KNAPSACK'])\n",
    "    new_node, total_fitness = cul_fitness(new_node)\n",
    "    #plot_fig(new_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee64b28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 1.0 637010.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (5) does not match length of index (494)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfitness_calculation\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_constants\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mfitness_calculation\u001b[1;34m(a, nodes_df, items_df, dict_constants)\u001b[0m\n\u001b[0;32m      6\u001b[0m random_node\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_index\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m random_item \u001b[38;5;241m=\u001b[39m a[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 9\u001b[0m new_node \u001b[38;5;241m=\u001b[39m \u001b[43mcul_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodes_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mdict_constants\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMIN SPEED\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_constants\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMAX SPEED\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_constants\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCAPACITY OF KNAPSACK\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m new_node, total_fitness \u001b[38;5;241m=\u001b[39m cul_fitness(new_node)\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mcul_time\u001b[1;34m(node, n_df, item, i_df, min_sp, max_sp, capacity)\u001b[0m\n\u001b[0;32m      7\u001b[0m di_df \u001b[38;5;241m=\u001b[39m cul_dis(node, n_df)\n\u001b[0;32m      8\u001b[0m node[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m di_df\n\u001b[1;32m----> 9\u001b[0m i_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m item\n\u001b[0;32m     10\u001b[0m new_i_df \u001b[38;5;241m=\u001b[39m i_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     11\u001b[0m new_i_df \u001b[38;5;241m=\u001b[39m new_i_df[new_i_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3978\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3978\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py:4172\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4163\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4164\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4165\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4170\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4172\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4175\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4176\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4177\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4178\u001b[0m     ):\n\u001b[0;32m   4179\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4180\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py:4912\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4909\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4911\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4912\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\pandas\\core\\common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    565\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (5) does not match length of index (494)"
     ]
    }
   ],
   "source": [
    "fitness_calculation(a, nodes_df, items_df, dict_constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f432c011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
